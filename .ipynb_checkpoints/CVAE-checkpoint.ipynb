{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5630c70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from preprocess import extract_images\n",
    "from dataset import get_full_list, ChineseCharacterDataset\n",
    "from models import CVAE\n",
    "from utils import visualize_images, show_images\n",
    "from loss import vae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8f76688",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b82c0d",
   "metadata": {},
   "source": [
    "### Loading and Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "383085cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory and load the dataset\n",
    "image_dir = './chinese_chars/pngs'\n",
    "full_data_list = get_full_list(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e134457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size: 9574\n"
     ]
    }
   ],
   "source": [
    "train_size = int(1*len(full_data_list))\n",
    "print(\"Training Set Size:\", train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93b1ee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_cols = ChineseCharacterDataset(full_data_list[:train_size], cond_type='Half')\n",
    "\n",
    "# Create data loaders\n",
    "train_loader_cols = DataLoader(train_data_cols, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a40d89",
   "metadata": {},
   "source": [
    "### Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a8bb9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2fbecde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "def train(model, train_data_set, input_dim, optimizer, scheduler, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_idx, (data, condition) in enumerate(train_data_set):\n",
    "            print(f'Batch {batch_idx}/{len(train_data_set)} for epoch {epoch+1}')\n",
    "            data = data.to(device)\n",
    "            condition = condition.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed_batch, mu, logvar = model(data, condition)\n",
    "            loss = vae_loss(reconstructed_batch.view(data.shape[0],1,64,64), data, mu, logvar)\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "        print(f'Epoch {epoch+1}, Loss: {train_loss/len(train_data_set.dataset)}')\n",
    "    print(f'Final Loss: {train_loss/len(train_data_set.dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c18358f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training now\n",
      "Batch 0/300 for epoch 1\n",
      "Batch 1/300 for epoch 1\n",
      "Batch 2/300 for epoch 1\n",
      "Batch 3/300 for epoch 1\n",
      "Batch 4/300 for epoch 1\n",
      "Batch 5/300 for epoch 1\n",
      "Batch 6/300 for epoch 1\n",
      "Batch 7/300 for epoch 1\n",
      "Batch 8/300 for epoch 1\n",
      "Batch 9/300 for epoch 1\n",
      "Batch 10/300 for epoch 1\n",
      "Batch 11/300 for epoch 1\n",
      "Batch 12/300 for epoch 1\n",
      "Batch 13/300 for epoch 1\n",
      "Batch 14/300 for epoch 1\n",
      "Batch 15/300 for epoch 1\n",
      "Batch 16/300 for epoch 1\n",
      "Batch 17/300 for epoch 1\n",
      "Batch 18/300 for epoch 1\n",
      "Batch 19/300 for epoch 1\n",
      "Batch 20/300 for epoch 1\n",
      "Batch 21/300 for epoch 1\n",
      "Batch 22/300 for epoch 1\n"
     ]
    }
   ],
   "source": [
    "input_dim = 64 * 64\n",
    "z_dim = 50\n",
    "condition_dim = 50\n",
    "hidden_dim = 6400*10\n",
    "learning_rate = 1e-3\n",
    "\n",
    "num_epochs = 40\n",
    "\n",
    "model_cols = CVAE(input_dim, hidden_dim, z_dim, condition_dim).to(device)\n",
    "optimizer = optim.Adam(model_cols.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "print(\"training now\")\n",
    "train(model_cols, train_loader_cols, input_dim, optimizer, scheduler, num_epochs) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4e330e",
   "metadata": {},
   "source": [
    "### Generating Images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10292d84",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def plot_generated_images(model, data_loader, num_images, batch_size, device='cpu'):\n",
    "    model.eval()\n",
    "    left_images = num_images\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, condition) in enumerate(data_loader):\n",
    "            condition = condition.to(device)\n",
    "            data = data.to(device)\n",
    "            if left_images == 0:\n",
    "                break\n",
    "            \n",
    "            z = torch.randn(batch_size, model.z_dim).to(device)\n",
    "            cond_encoded = model.forward_condition_encoder(condition)\n",
    "            sample = model.decode(z, cond_encoded).cpu()\n",
    "            sample = sample.view(batch_size, 1, 64, 64)\n",
    "            \n",
    "            if left_images > batch_size:\n",
    "                print_images = batch_size\n",
    "                left_images = left_images-batch_size\n",
    "            else:\n",
    "                print_images = left_images\n",
    "                left_images = 0\n",
    "\n",
    "            for i in range(print_images):\n",
    "                ref = data[i].cpu().detach().numpy().reshape(64, 64)\n",
    "                img = sample[i].cpu().detach().numpy().reshape(64, 64)\n",
    "                \n",
    "                # Handle condition image with random shape\n",
    "                cond = condition[i].cpu().detach().numpy()\n",
    "                if len(cond.shape) > 2:\n",
    "                    cond = cond[0]  # Select the first channel if condition is multi-channel\n",
    "                cond_shape = cond.shape\n",
    "                cond_resized = cond.reshape(cond_shape)\n",
    "\n",
    "                plt.figure(figsize=(12, 4))\n",
    "\n",
    "                # Plot condition image\n",
    "                plt.subplot(1, 3, 1)\n",
    "                plt.title('Condition Image')\n",
    "                plt.imshow(cond_resized, cmap='gray')\n",
    "                plt.axis('off')\n",
    "\n",
    "                # Plot reference image\n",
    "                plt.subplot(1, 3, 2)\n",
    "                plt.title('Reference Image')\n",
    "                plt.imshow(ref, cmap='gray')\n",
    "                plt.axis('off')\n",
    "\n",
    "                # Plot generated image\n",
    "                plt.subplot(1, 3, 3)\n",
    "                plt.title('Generated Image')\n",
    "                plt.imshow(img, cmap='gray')\n",
    "                plt.axis('off')\n",
    "\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "plot_generated_images(model_cols, train_loader_cols, num_images=5, batch_size=32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6ee7ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac4bb21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
